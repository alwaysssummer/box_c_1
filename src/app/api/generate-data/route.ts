import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import Anthropic from '@anthropic-ai/sdk'
import { GoogleGenerativeAI } from '@google/generative-ai'
import { createClient } from '@/lib/supabase/server'
import { createDetailedError, getAlternativeModel } from '@/lib/ai-errors'
import { isBaseDataType } from '@/lib/constants/base-data-types'
import { fetchBaseData } from '@/lib/utils/base-data-fetcher'

// AI ëª¨ë¸ ì •ì˜ (test-promptì™€ ë™ì¼)
export const AI_MODELS = {
  'gpt-4o': { provider: 'openai', name: 'GPT-4o', description: 'ìµœì‹  ê³ ì„±ëŠ¥ ëª¨ë¸' },
  'gpt-4o-mini': { provider: 'openai', name: 'GPT-4o Mini', description: 'ë¹ ë¥´ê³  ì €ë ´' },
  'gpt-3.5-turbo': { provider: 'openai', name: 'GPT-3.5 Turbo', description: 'ê°€ì¥ ì €ë ´' },
  'claude-3-5-sonnet-20241022': { provider: 'anthropic', name: 'Claude 3.5 Sonnet', description: 'ê³ ì„±ëŠ¥' },
  'claude-3-haiku-20240307': { provider: 'anthropic', name: 'Claude 3 Haiku', description: 'ë¹ ë¦„' },
  'gemini-1.5-pro': { provider: 'google', name: 'Gemini 1.5 Pro', description: 'ê³ ì„±ëŠ¥, ê¸´ ì»¨í…ìŠ¤íŠ¸' },
  'gemini-2.0-flash': { provider: 'google', name: 'âš¡ Gemini 2.0 Flash (ì¶”ì²œ)', description: 'ë¹ ë¥´ê³  ì €ë ´í•œ ì¶”ì²œ ëª¨ë¸' },
  'gemini-2.5-flash': { provider: 'google', name: 'ğŸš€ Gemini 2.5 Flash (ìµœì‹ )', description: 'ìµœì‹  ê³ ì† ëª¨ë¸' },
} as const

type ModelId = keyof typeof AI_MODELS

// ============================================
// ìš”ì²­/ì‘ë‹µ íƒ€ì…
// ============================================

interface GenerateDataRequest {
  passageId: string          // ì§€ë¬¸ ID
  sentenceId?: string | null // ë¬¸ì¥ ID (ë¬¸ì¥ ë‹¨ìœ„ ìƒì„± ì‹œ)
  dataTypeId: string         // ë°ì´í„° ìœ í˜• ID
  model?: ModelId            // AI ëª¨ë¸ (ë¯¸ì§€ì • ì‹œ ë°ì´í„° ìœ í˜•ì˜ ì¶”ì²œ ëª¨ë¸ ì‚¬ìš©)
  skipSave?: boolean         // trueë©´ DB ì €ì¥ ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜ (ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ)
}

interface GenerateDataResponse {
  success: boolean
  data?: {
    id: string
    passageId: string
    sentenceId: string | null
    dataTypeId: string
    result: unknown
    status: string
    modelUsed: string
    confidence: number | null
    responseTime: number
    inputTokens: number
    outputTokens: number
  }
  error?: string
  aiError?: {
    type: string
    message: string
    solution: string
    severity?: string
    canRetry: boolean
    alternativeModel?: string | null
  }
}

// ============================================
// AI í˜¸ì¶œ í•¨ìˆ˜ë“¤
// ============================================

async function callOpenAI(
  model: string,
  systemPrompt: string,
  userPrompt: string
): Promise<{ result: string; usage: { inputTokens: number; outputTokens: number } }> {
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
  })

  const response = await openai.chat.completions.create({
    model,
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ],
    temperature: 0.3, // ë°ì´í„° ìƒì„±ì€ ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± ìœ ì§€
    response_format: { type: 'json_object' },
  })

  return {
    result: response.choices[0]?.message?.content || '',
    usage: {
      inputTokens: response.usage?.prompt_tokens || 0,
      outputTokens: response.usage?.completion_tokens || 0,
    },
  }
}

async function callAnthropic(
  model: string,
  systemPrompt: string,
  userPrompt: string
): Promise<{ result: string; usage: { inputTokens: number; outputTokens: number } }> {
  const anthropic = new Anthropic({
    apiKey: process.env.ANTHROPIC_API_KEY,
  })

  const response = await anthropic.messages.create({
    model,
    max_tokens: 4096,
    system: systemPrompt,
    messages: [{ role: 'user', content: userPrompt }],
  })

  const textContent = response.content.find((c) => c.type === 'text')
  
  return {
    result: textContent?.type === 'text' ? textContent.text : '',
    usage: {
      inputTokens: response.usage.input_tokens,
      outputTokens: response.usage.output_tokens,
    },
  }
}

async function callGemini(
  model: string,
  systemPrompt: string,
  userPrompt: string
): Promise<{ result: string; usage: { inputTokens: number; outputTokens: number } }> {
  const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY || '')
  const geminiModel = genAI.getGenerativeModel({ 
    model,
    systemInstruction: systemPrompt,
    generationConfig: {
      responseMimeType: 'application/json',
      temperature: 0.3,
    },
  })

  const result = await geminiModel.generateContent(userPrompt)
  const response = result.response
  const usageMetadata = response.usageMetadata
  
  return {
    result: response.text(),
    usage: {
      inputTokens: usageMetadata?.promptTokenCount || 0,
      outputTokens: usageMetadata?.candidatesTokenCount || 0,
    },
  }
}

// ============================================
// ë³€ìˆ˜ ì¹˜í™˜
// ============================================

function replaceVariables(
  prompt: string, 
  passage: { content: string; korean_translation: string | null },
  sentence?: { content: string; korean_translation: string | null }
): string {
  let result = prompt
  
  // ì§€ë¬¸ ë³€ìˆ˜
  result = result.replace(/\[\[passage\]\]/g, passage.content || '')
  result = result.replace(/\[\[korean\]\]/g, passage.korean_translation || '')
  
  // ë¬¸ì¥ ë³€ìˆ˜ (ë¬¸ì¥ ë‹¨ìœ„ ìƒì„± ì‹œ)
  if (sentence) {
    result = result.replace(/\[\[sentence\]\]/g, sentence.content || '')
    result = result.replace(/\[\[sentence_korean\]\]/g, sentence.korean_translation || '')
  }
  
  return result
}

// ============================================
// POST /api/generate-data - ë°ì´í„° ìƒì„±
// ============================================

export async function POST(request: NextRequest) {
  const startTime = Date.now()
  const supabase = await createClient()
  
  try {
    const body: GenerateDataRequest = await request.json()
    const { passageId, sentenceId, dataTypeId, model: requestedModel, skipSave } = body

    // í•„ìˆ˜ í•„ë“œ ê²€ì¦
    if (!passageId || !dataTypeId) {
      return NextResponse.json<GenerateDataResponse>(
        { success: false, error: 'í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤ (passageId, dataTypeId)' },
        { status: 400 }
      )
    }

    // 1. ë°ì´í„° ìœ í˜• ì¡°íšŒ (í”„ë¡¬í”„íŠ¸ ì •ë³´ í¬í•¨)
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const { data: dataType, error: dataTypeError } = await (supabase as any)
      .from('data_types')
      .select(`
        *,
        prompt:prompts!data_types_prompt_id_fkey (
          id,
          content,
          output_schema,
          variables
        )
      `)
      .eq('id', dataTypeId)
      .single()

    if (dataTypeError || !dataType) {
      return NextResponse.json<GenerateDataResponse>(
        { success: false, error: 'ë°ì´í„° ìœ í˜•ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' },
        { status: 404 }
      )
    }

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const dtAnyCategory = dataType as any

    // ============================================
    // 2. ê¸°ë³¸ ë°ì´í„° ìœ í˜• ì²˜ë¦¬ (AI í˜¸ì¶œ ìŠ¤í‚µ)
    // ============================================
    if (dtAnyCategory.category === 'base' || isBaseDataType(dataTypeId)) {
      const baseResult = await fetchBaseData(passageId, dataTypeId)
      const responseTime = Date.now() - startTime

      if (!baseResult.success) {
        return NextResponse.json<GenerateDataResponse>(
          { success: false, error: baseResult.error || 'ê¸°ë³¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨' },
          { status: 500 }
        )
      }

      // skipSaveê°€ trueë©´ DB ì €ì¥ ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜ (ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ)
      if (skipSave) {
        return NextResponse.json<GenerateDataResponse>({
          success: true,
          data: {
            id: '', // ì•„ì§ ì €ì¥ ì•ˆ ë¨
            passageId,
            sentenceId: sentenceId || null,
            dataTypeId,
            result: baseResult.data,
            status: 'preview', // ë¯¸ë¦¬ë³´ê¸° ìƒíƒœ
            modelUsed: 'none',
            confidence: 1.0,
            responseTime,
            inputTokens: 0,
            outputTokens: 0,
          },
        })
      }

      // DBì— ì €ì¥ (ê¸°ì¡´ ë°ì´í„° í™•ì¸ í›„ INSERT ë˜ëŠ” UPDATE)
      // ê¸°ì¡´ ë°ì´í„° í™•ì¸
      let existingQuery = supabase
        .from('generated_data')
        .select('id')
        .eq('passage_id', passageId)
        .eq('data_type_id', dataTypeId)
      
      if (sentenceId) {
        existingQuery = existingQuery.eq('sentence_id', sentenceId)
      } else {
        existingQuery = existingQuery.is('sentence_id', null)
      }
      
      const { data: existingData } = await existingQuery.single()
      
      let savedData: { id: string } | null = null
      let saveError: Error | null = null
      
      const dataToSave = {
        passage_id: passageId,
        sentence_id: sentenceId || null,
        data_type_id: dataTypeId,
        result: baseResult.data,
        status: 'completed',
        model_used: 'none',
        confidence: 1.0,
        response_time: responseTime,
        input_tokens: 0,
        output_tokens: 0,
        error_message: null,
      }
      
      if (existingData?.id) {
        // UPDATE
        const { data, error } = await supabase
          .from('generated_data')
          .update(dataToSave)
          .eq('id', existingData.id)
          .select('id')
          .single()
        savedData = data
        saveError = error
      } else {
        // INSERT
        const { data, error } = await supabase
          .from('generated_data')
          .insert(dataToSave)
          .select('id')
          .single()
        savedData = data
        saveError = error
      }

      if (saveError) {
        console.error('Error saving base data:', saveError)
      }

      return NextResponse.json<GenerateDataResponse>({
        success: true,
        data: {
          id: savedData?.id || '',
          passageId,
          sentenceId: sentenceId || null,
          dataTypeId,
          result: baseResult.data,
          status: 'completed',
          modelUsed: 'none',
          confidence: 1.0,
          responseTime,
          inputTokens: 0,
          outputTokens: 0,
        },
      })
    }

    // ============================================
    // 3. AI ë°ì´í„° ìœ í˜• ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
    // ============================================

    // í”„ë¡¬í”„íŠ¸ í™•ì¸
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const promptContent = (dataType as any).prompt?.content || (dataType as any).prompt
    if (!promptContent) {
      return NextResponse.json<GenerateDataResponse>(
        { success: false, error: 'ë°ì´í„° ìœ í˜•ì— ì—°ê²°ëœ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤' },
        { status: 400 }
      )
    }

    // 4. ì§€ë¬¸ ì¡°íšŒ
    const { data: passage, error: passageError } = await supabase
      .from('passages')
      .select('id, content, korean_translation')
      .eq('id', passageId)
      .single()

    if (passageError || !passage) {
      return NextResponse.json<GenerateDataResponse>(
        { success: false, error: 'ì§€ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' },
        { status: 404 }
      )
    }

    // 5. ë¬¸ì¥ ì¡°íšŒ (ë¬¸ì¥ ë‹¨ìœ„ ìƒì„± ì‹œ)
    let sentence = null
    if (sentenceId) {
      const { data: sentenceData, error: sentenceError } = await supabase
        .from('sentences')
        .select('id, content, korean_translation')
        .eq('id', sentenceId)
        .single()

      if (sentenceError || !sentenceData) {
        return NextResponse.json<GenerateDataResponse>(
          { success: false, error: 'ë¬¸ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' },
          { status: 404 }
        )
      }
      sentence = sentenceData
    }

    // 6. ëª¨ë¸ ê²°ì •
    const model = (requestedModel || dtAnyCategory.recommended_model || 'gpt-4o-mini') as ModelId
    const modelInfo = AI_MODELS[model] as { provider: string; name: string; description: string } | undefined
    
    if (!modelInfo) {
      return NextResponse.json<GenerateDataResponse>(
        { success: false, error: `ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤: ${model}` },
        { status: 400 }
      )
    }

    // 7. í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
    const processedPrompt = replaceVariables(promptContent, passage, sentence || undefined)
    
    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    let systemPrompt = 'ë‹¹ì‹ ì€ ì˜ì–´ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.'
    const outputSchema = dtAnyCategory.prompt?.output_schema || dtAnyCategory.output_schema
    if (outputSchema) {
      systemPrompt += `\n\në‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì—„ê²©íˆ ë”°ë¥´ì„¸ìš”:\n${typeof outputSchema === 'string' ? outputSchema : JSON.stringify(outputSchema, null, 2)}`
    }

    // 8. AI í˜¸ì¶œ
    let aiResult: { result: string; usage: { inputTokens: number; outputTokens: number } }

    switch (modelInfo.provider) {
      case 'openai':
        if (!process.env.OPENAI_API_KEY) {
          throw new Error('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
        }
        aiResult = await callOpenAI(model, systemPrompt, processedPrompt)
        break
        
      case 'anthropic':
        if (!process.env.ANTHROPIC_API_KEY) {
          throw new Error('ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
        }
        aiResult = await callAnthropic(model, systemPrompt, processedPrompt)
        break
        
      case 'google':
        if (!process.env.GOOGLE_GEMINI_API_KEY) {
          throw new Error('GOOGLE_GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
        }
        aiResult = await callGemini(model, systemPrompt, processedPrompt)
        break
        
      default:
        throw new Error(`ì•Œ ìˆ˜ ì—†ëŠ” ì œê³µì—…ì²´: ${modelInfo.provider}`)
    }

    const responseTime = Date.now() - startTime

    // 9. JSON íŒŒì‹±
    let parsedResult: unknown
    try {
      parsedResult = JSON.parse(aiResult.result)
    } catch {
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥
      parsedResult = { raw_text: aiResult.result }
    }

    // 10. skipSaveê°€ trueë©´ DB ì €ì¥ ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜ (ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ)
    if (skipSave) {
      return NextResponse.json<GenerateDataResponse>({
        success: true,
        data: {
          id: '', // ì•„ì§ ì €ì¥ ì•ˆ ë¨
          passageId,
          sentenceId: sentenceId || null,
          dataTypeId,
          result: parsedResult,
          status: 'preview', // ë¯¸ë¦¬ë³´ê¸° ìƒíƒœ
          modelUsed: model,
          confidence: 0.95,
          responseTime,
          inputTokens: aiResult.usage.inputTokens,
          outputTokens: aiResult.usage.outputTokens,
        },
      })
    }

    // DBì— ì €ì¥ (ê¸°ì¡´ ë°ì´í„° í™•ì¸ í›„ INSERT ë˜ëŠ” UPDATE)
    let existingQueryAI = supabase
      .from('generated_data')
      .select('id')
      .eq('passage_id', passageId)
      .eq('data_type_id', dataTypeId)
    
    if (sentenceId) {
      existingQueryAI = existingQueryAI.eq('sentence_id', sentenceId)
    } else {
      existingQueryAI = existingQueryAI.is('sentence_id', null)
    }
    
    const { data: existingDataAI } = await existingQueryAI.single()
    
    let savedDataAI: { id: string } | null = null
    let saveErrorAI: Error | null = null
    
    const aiDataToSave = {
      passage_id: passageId,
      sentence_id: sentenceId || null,
      data_type_id: dataTypeId,
      result: parsedResult,
      status: 'completed',
      model_used: model,
      confidence: 0.95,
      response_time: responseTime,
      input_tokens: aiResult.usage.inputTokens,
      output_tokens: aiResult.usage.outputTokens,
      error_message: null,
    }
    
    if (existingDataAI?.id) {
      // UPDATE
      const { data, error } = await supabase
        .from('generated_data')
        .update(aiDataToSave)
        .eq('id', existingDataAI.id)
        .select('id')
        .single()
      savedDataAI = data
      saveErrorAI = error
    } else {
      // INSERT
      const { data, error } = await supabase
        .from('generated_data')
        .insert(aiDataToSave)
        .select('id')
        .single()
      savedDataAI = data
      saveErrorAI = error
    }

    if (saveErrorAI) {
      console.error('Error saving generated data:', saveErrorAI)
      // ì €ì¥ ì‹¤íŒ¨í•´ë„ ê²°ê³¼ëŠ” ë°˜í™˜
    }

    return NextResponse.json<GenerateDataResponse>({
      success: true,
      data: {
        id: savedDataAI?.id || '',
        passageId,
        sentenceId: sentenceId || null,
        dataTypeId,
        result: parsedResult,
        status: 'completed',
        modelUsed: model,
        confidence: 0.95,
        responseTime,
        inputTokens: aiResult.usage.inputTokens,
        outputTokens: aiResult.usage.outputTokens,
      },
    })

  } catch (error) {
    const responseTime = Date.now() - startTime
    
    // ì—ëŸ¬ ì •ë³´ ì¶”ì¶œ
    const body = await request.clone().json().catch(() => ({}))
    const model = body.model || 'gpt-4o-mini'
    
    // ìƒì„¸ ì—ëŸ¬ ë¶„ë¥˜
    const detailedError = createDetailedError(error, {
      model,
      provider: AI_MODELS[model as ModelId]?.provider,
      action: 'data-generation'
    })
    
    const alternativeModel = getAlternativeModel(model, detailedError.errorInfo.type)
    
    console.error('Data generation error:', {
      errorType: detailedError.errorInfo.type,
      message: detailedError.errorInfo.message,
      originalError: detailedError.originalError,
      model,
    })

    // ì‹¤íŒ¨ ìƒíƒœë¡œ DB ì €ì¥ ì‹œë„
    if (body.passageId && body.dataTypeId) {
      try {
        const supabase = await createClient()
        
        // ê¸°ì¡´ ë°ì´í„° í™•ì¸
        let existingQueryFail = supabase
          .from('generated_data')
          .select('id')
          .eq('passage_id', body.passageId)
          .eq('data_type_id', body.dataTypeId)
        
        if (body.sentenceId) {
          existingQueryFail = existingQueryFail.eq('sentence_id', body.sentenceId)
        } else {
          existingQueryFail = existingQueryFail.is('sentence_id', null)
        }
        
        const { data: existingFail } = await existingQueryFail.single()
        
        const failDataToSave = {
          passage_id: body.passageId,
          sentence_id: body.sentenceId || null,
          data_type_id: body.dataTypeId,
          status: 'failed',
          error_message: detailedError.errorInfo.message,
          model_used: model,
          response_time: responseTime,
        }
        
        if (existingFail?.id) {
          await supabase
            .from('generated_data')
            .update(failDataToSave)
            .eq('id', existingFail.id)
        } else {
          await supabase
            .from('generated_data')
            .insert(failDataToSave)
        }
      } catch (saveErr) {
        console.error('Failed to save error status:', saveErr)
      }
    }
    
    return NextResponse.json<GenerateDataResponse>({
      success: false,
      error: `${detailedError.errorInfo.icon} ${detailedError.errorInfo.message}`,
      aiError: {
        type: detailedError.errorInfo.type,
        message: detailedError.errorInfo.message,
        solution: detailedError.errorInfo.solution,
        severity: detailedError.errorInfo.severity,
        canRetry: detailedError.errorInfo.canRetry,
        alternativeModel,
      },
    })
  }
}

// ============================================
// GET /api/generate-data - ìƒì„±ëœ ë°ì´í„° ì¡°íšŒ
// ============================================

export async function GET(request: NextRequest) {
  try {
    const supabase = await createClient()
    const { searchParams } = new URL(request.url)
    
    const passageId = searchParams.get('passageId')
    const dataTypeId = searchParams.get('dataTypeId')
    const status = searchParams.get('status')
    
    let query = supabase
      .from('generated_data')
      .select(`
        *,
        passage:passages!generated_data_passage_id_fkey (
          id, name, content
        ),
        data_type:data_types!generated_data_data_type_id_fkey (
          id, name, target
        ),
        sentence:sentences!generated_data_sentence_id_fkey (
          id, sentence_no, content
        )
      `)
      .order('created_at', { ascending: false })
    
    if (passageId) {
      query = query.eq('passage_id', passageId)
    }
    
    if (dataTypeId) {
      query = query.eq('data_type_id', dataTypeId)
    }
    
    if (status) {
      query = query.eq('status', status)
    }
    
    const { data, error } = await query
    
    if (error) {
      throw error
    }
    
    return NextResponse.json({ success: true, data })
    
  } catch (error) {
    console.error('Error fetching generated data:', error)
    return NextResponse.json(
      { success: false, error: 'Failed to fetch generated data' },
      { status: 500 }
    )
  }
}

// ============================================
// PUT /api/generate-data - ë¯¸ë¦¬ë³´ê¸° ê²°ê³¼ ì¼ê´„ ì €ì¥
// ============================================

interface SaveDataItem {
  passageId: string
  sentenceId?: string | null
  dataTypeId: string
  result: unknown
  modelUsed: string
  confidence: number
  responseTime: number
  inputTokens: number
  outputTokens: number
}

export async function PUT(request: NextRequest) {
  try {
    const supabase = await createClient()
    const body: { items: SaveDataItem[] } = await request.json()
    
    if (!body.items || !Array.isArray(body.items) || body.items.length === 0) {
      return NextResponse.json(
        { success: false, error: 'ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤' },
        { status: 400 }
      )
    }
    
    const results: { passageId: string; success: boolean; error?: string }[] = []
    
    for (const item of body.items) {
      try {
        // ê¸°ì¡´ ë°ì´í„° í™•ì¸
        let existingQuery = supabase
          .from('generated_data')
          .select('id')
          .eq('passage_id', item.passageId)
          .eq('data_type_id', item.dataTypeId)
        
        if (item.sentenceId) {
          existingQuery = existingQuery.eq('sentence_id', item.sentenceId)
        } else {
          existingQuery = existingQuery.is('sentence_id', null)
        }
        
        const { data: existingData } = await existingQuery.single()
        
        const dataToSave = {
          passage_id: item.passageId,
          sentence_id: item.sentenceId || null,
          data_type_id: item.dataTypeId,
          result: item.result,
          status: 'completed',
          model_used: item.modelUsed,
          confidence: item.confidence,
          response_time: item.responseTime,
          input_tokens: item.inputTokens,
          output_tokens: item.outputTokens,
          error_message: null,
        }
        
        if (existingData?.id) {
          // UPDATE
          const { error } = await supabase
            .from('generated_data')
            .update(dataToSave)
            .eq('id', existingData.id)
          
          if (error) throw error
        } else {
          // INSERT
          const { error } = await supabase
            .from('generated_data')
            .insert(dataToSave)
          
          if (error) throw error
        }
        
        results.push({ passageId: item.passageId, success: true })
      } catch (err) {
        results.push({ 
          passageId: item.passageId, 
          success: false, 
          error: err instanceof Error ? err.message : 'ì €ì¥ ì‹¤íŒ¨' 
        })
      }
    }
    
    const successCount = results.filter(r => r.success).length
    const failCount = results.filter(r => !r.success).length
    
    return NextResponse.json({
      success: failCount === 0,
      message: `ì €ì¥ ì™„ë£Œ: ì„±ê³µ ${successCount}ê°œ, ì‹¤íŒ¨ ${failCount}ê°œ`,
      results,
    })
    
  } catch (error) {
    console.error('Error saving generated data batch:', error)
    return NextResponse.json(
      { success: false, error: 'Failed to save generated data' },
      { status: 500 }
    )
  }
}

