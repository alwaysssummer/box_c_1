import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import Anthropic from '@anthropic-ai/sdk'
import { GoogleGenerativeAI } from '@google/generative-ai'
import { splitSentences, analyzeTranslation, splitSentencesByRegex, calculateOverallConfidence } from '@/lib/sentence-splitter'
import { AI_MODELS, ModelId, ParsedSentence, SentenceSplitResult, KoreanIssue, SentencePair } from '@/types'
import { classifyAIError, createDetailedError, getAlternativeModel, AIErrorInfo } from '@/lib/ai-errors'

// AI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
let openai: OpenAI | null = null
let anthropic: Anthropic | null = null
let genAI: GoogleGenerativeAI | null = null

// ğŸ”§ API í‚¤ ìƒíƒœ ë¡œê¹… (ì„œë²„ ì‹œì‘ ì‹œ)
console.log('=== AI API í‚¤ ìƒíƒœ ===')
console.log('GOOGLE_GEMINI_API_KEY:', process.env.GOOGLE_GEMINI_API_KEY ? `ì„¤ì •ë¨ (${process.env.GOOGLE_GEMINI_API_KEY.substring(0, 10)}...)` : 'âŒ ë¯¸ì„¤ì •')
console.log('OPENAI_API_KEY:', process.env.OPENAI_API_KEY ? `ì„¤ì •ë¨ (${process.env.OPENAI_API_KEY.substring(0, 10)}...)` : 'âŒ ë¯¸ì„¤ì •')
console.log('ANTHROPIC_API_KEY:', process.env.ANTHROPIC_API_KEY ? `ì„¤ì •ë¨ (${process.env.ANTHROPIC_API_KEY.substring(0, 10)}...)` : 'âŒ ë¯¸ì„¤ì •')
console.log('======================')

function getOpenAI() {
  if (!openai && process.env.OPENAI_API_KEY) {
    openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
  }
  return openai
}

function getAnthropic() {
  if (!anthropic && process.env.ANTHROPIC_API_KEY) {
    anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY })
  }
  return anthropic
}

function getGoogleAI() {
  if (!genAI && process.env.GOOGLE_GEMINI_API_KEY) {
    genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY)
  }
  return genAI
}

// AI ë¬¸ì¥ ë¶„ë¦¬ í”„ë¡¬í”„íŠ¸ (ê°•í™” ë²„ì „)
const SENTENCE_SPLIT_PROMPT = `You are an expert at splitting English text into grammatically complete sentences.

**CRITICAL RULES (MUST FOLLOW):**
1. **NEVER modify the original text** - preserve every character, space, and punctuation EXACTLY as given
2. Each sentence must be grammatically complete
3. Handle abbreviations correctly (Dr., Mr., Mrs., Ms., U.S., U.K., e.g., i.e., etc., vs.) - do NOT split at these
4. Quoted text with punctuation inside (e.g., "wrong." or "Hello!") - the quote is part of the sentence
5. Sentences end with: period(.), exclamation(!), question(?)
6. Quote marks can follow ending punctuation: ."  !"  ?"

**VALIDATION:**
- When you concatenate all sentence contents with single spaces, it MUST exactly match the original text
- Do NOT add, remove, change, or correct any characters

Output format (JSON only, no markdown):
{
  "sentences": [
    {"no": 1, "content": "First sentence exactly as original.", "confidence": 0.95}
  ],
  "overall_confidence": 0.96
}

Confidence: 0.0-1.0, lower for abbreviations/quotes/complex punctuation.

Text to split:`

// ë²ˆì—­ ê²€ì¦/ìƒì„± í”„ë¡¬í”„íŠ¸
const TRANSLATION_VERIFY_PROMPT = `You are a translation quality checker. Verify if the Korean translation matches the English sentence.

Output format (JSON only):
{
  "score": 8,
  "issues": ["Minor issues if any"],
  "suggestion": "Better translation if needed, or null if good"
}

Score: 1-10 (10 = perfect match)

English:`

/**
 * AIë¥¼ ì‚¬ìš©í•œ ë¬¸ì¥ ë¶„ë¦¬
 */
async function splitWithAI(
  text: string,
  model: ModelId,
  koreanText?: string | null
): Promise<SentenceSplitResult> {
  const startTime = Date.now()
  
  const prompt = `${SENTENCE_SPLIT_PROMPT}
"${text}"

${koreanText ? `
Korean translation (for reference, try to match sentence counts):
"${koreanText}"` : ''}`

  let resultText = ''
  const modelInfo = AI_MODELS[model]

  try {
    switch (modelInfo.provider) {
      case 'openai': {
        const client = getOpenAI()
        if (!client) throw new Error('OpenAI API key not configured')
        
        const response = await client.chat.completions.create({
          model,
          messages: [{ role: 'user', content: prompt }],
          response_format: { type: 'json_object' },
          temperature: 0.1,
        })
        resultText = response.choices[0].message?.content || ''
        break
      }
      
      case 'anthropic': {
        const client = getAnthropic()
        if (!client) throw new Error('Anthropic API key not configured')
        
        const response = await client.messages.create({
          model,
          max_tokens: 4096,
          messages: [{ role: 'user', content: prompt }],
        })
        resultText = response.content[0]?.type === 'text' ? response.content[0].text : ''
        break
      }
      
      case 'google': {
        const client = getGoogleAI()
        if (!client) throw new Error('Google Gemini API key not configured')
        
        const geminiModel = client.getGenerativeModel({ 
          model,
          generationConfig: {
            responseMimeType: 'application/json',
            temperature: 0.1,
          }
        })
        const response = await geminiModel.generateContent(prompt)
        resultText = response.response.text()
        break
      }
      
      default:
        throw new Error(`Unsupported model provider: ${modelInfo.provider}`)
    }

    // JSON íŒŒì‹±
    const parsed = JSON.parse(resultText)
    
    // í•œê¸€ ë²ˆì—­ ë§¤ì¹­ (ìˆëŠ” ê²½ìš°)
    let sentences: ParsedSentence[] = parsed.sentences.map((s: { no: number; content: string; confidence?: number }) => ({
      no: s.no,
      content: s.content,
      wordCount: s.content.split(/\s+/).length,
      confidence: s.confidence || 0.9,
      issues: [],
    }))

    // í•œê¸€ ë²ˆì—­ ë§¤ì¹­
    if (koreanText) {
      const koreanSentences = koreanText
        .split(/(?<=[.!?ë‹¤ìš”ì£ ìŒí•¨])\s+/)
        .map(s => s.trim())
        .filter(s => s.length > 0)

      if (koreanSentences.length === sentences.length) {
        sentences = sentences.map((s, idx) => ({
          ...s,
          koreanTranslation: koreanSentences[idx],
        }))
      }
    }

    return {
      sentences,
      confidence: parsed.overall_confidence || 0.95,
      method: 'ai',
      model,
    }
  } catch (error) {
    console.error('AI sentence split error:', error)
    throw error
  }
}

/**
 * í•˜ì´ë¸Œë¦¬ë“œ ë¬¸ì¥ ë¶„ë¦¬ (Regex + AI ê²€ì¦)
 */
async function splitHybrid(
  text: string,
  model: ModelId,
  koreanText?: string | null
): Promise<SentenceSplitResult> {
  // 1ë‹¨ê³„: Regex ë¶„ë¦¬
  const regexResult = splitSentences(text, koreanText)
  
  // ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
  if (regexResult.confidence >= 0.9 && (!regexResult.warnings || regexResult.warnings.length === 0)) {
    return {
      ...regexResult,
      method: 'regex',
    }
  }
  
  // 2ë‹¨ê³„: AI ê²€ì¦ í•„ìš”
  const aiResult = await splitWithAI(text, model, koreanText)
  return {
    ...aiResult,
    method: 'hybrid',
  }
}

/**
 * AI ê²€ì¦ ëª¨ë“œ - Regex ê²°ê³¼ë¥¼ AIê°€ í•­ìƒ ê²€ì¦/ìˆ˜ì • (ì›ë¬¸ ë³´ì¡´ í•„ìˆ˜)
 */
async function splitWithAIVerification(
  text: string,
  model: ModelId,
  koreanText?: string | null
): Promise<SentenceSplitResult> {
  // 1ë‹¨ê³„: Regex ë¶„ë¦¬
  const regexResult = splitSentences(text, koreanText)
  
  // 2ë‹¨ê³„: AIì—ê²Œ Regex ê²°ê³¼ ê²€ì¦ ìš”ì²­
  const verifyPrompt = `You are validating sentence boundaries. Your job is to verify and correct if needed.

**CRITICAL: The original text MUST be preserved EXACTLY. Never modify, correct, or paraphrase any character.**

Original text:
"${text}"

Regex split result (${regexResult.sentences.length} sentences):
${regexResult.sentences.map(s => `${s.no}. "${s.content}"`).join('\n')}

Review and correct the split if needed. Common issues:
1. Abbreviations (Dr., Mr., U.S., e.g., i.e.) should NOT cause splits
2. Quoted text ending with punctuation ("wrong." or "Hello!") - the quote ends the sentence
3. Each sentence must be grammatically complete

**VALIDATION REQUIREMENT:**
- Concatenating all your sentence contents with spaces must EXACTLY match the original text
- If you change anything in the text itself (not just splits), return the regex result unchanged

Output JSON only (no markdown):
{
  "sentences": [{"no": 1, "content": "exact text from original", "confidence": 0.95}],
  "overall_confidence": 0.96,
  "corrections": ["list of corrections made, or empty if none"]
}`

  const modelInfo = AI_MODELS[model]
  let resultText = ''

  try {
    switch (modelInfo.provider) {
      case 'openai': {
        const client = getOpenAI()
        if (!client) throw new Error('OpenAI API key not configured')
        const response = await client.chat.completions.create({
          model,
          messages: [{ role: 'user', content: verifyPrompt }],
          response_format: { type: 'json_object' },
          temperature: 0.1,
        })
        resultText = response.choices[0].message?.content || ''
        break
      }
      case 'anthropic': {
        const client = getAnthropic()
        if (!client) throw new Error('Anthropic API key not configured')
        const response = await client.messages.create({
          model,
          max_tokens: 4096,
          messages: [{ role: 'user', content: verifyPrompt }],
        })
        resultText = response.content[0]?.type === 'text' ? response.content[0].text : ''
        break
      }
      case 'google': {
        const client = getGoogleAI()
        if (!client) throw new Error('Google Gemini API key not configured')
        const geminiModel = client.getGenerativeModel({ 
          model,
          generationConfig: { responseMimeType: 'application/json', temperature: 0.1 }
        })
        const response = await geminiModel.generateContent(verifyPrompt)
        resultText = response.response.text()
        break
      }
      default:
        throw new Error(`Unsupported provider: ${modelInfo.provider}`)
    }

    const parsed = JSON.parse(resultText)
    
    // ì›ë¬¸ ê²€ì¦: AI ê²°ê³¼ê°€ ì›ë¬¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
    const aiText = parsed.sentences.map((s: { content: string }) => s.content).join(' ')
    const originalNormalized = text.replace(/\s+/g, ' ').trim()
    const aiNormalized = aiText.replace(/\s+/g, ' ').trim()
    
    if (originalNormalized !== aiNormalized) {
      console.error('AI modified original text - retry needed')
      console.error('Original:', originalNormalized.substring(0, 100))
      console.error('AI result:', aiNormalized.substring(0, 100))
      
      // AI ê²°ê³¼ ê±°ë¶€ - ì—ëŸ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¬ì‹œë„ ìœ ë„
      throw new Error('AI_TEXT_MODIFIED: AIê°€ ì›ë¬¸ì„ ë³€í˜•í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
    }

    // í•œê¸€ ë²ˆì—­ ë§¤ì¹­
    let sentences: ParsedSentence[] = parsed.sentences.map((s: { no: number; content: string; confidence?: number }) => ({
      no: s.no,
      content: s.content,
      wordCount: s.content.split(/\s+/).length,
      confidence: s.confidence || 0.95,
      issues: [],
    }))

    if (koreanText) {
      const koreanSentences = koreanText
        .split(/(?<=[.!?ë‹¤ìš”ì£ ìŒí•¨])\s+/)
        .map(s => s.trim())
        .filter(s => s.length > 0)

      if (koreanSentences.length === sentences.length) {
        sentences = sentences.map((s, idx) => ({
          ...s,
          koreanTranslation: koreanSentences[idx],
        }))
      }
    }

    return {
      sentences,
      confidence: parsed.overall_confidence || 0.95,
      method: 'ai-verify',
      model,
      warnings: parsed.corrections?.length > 0 ? parsed.corrections : undefined,
    }
  } catch (error) {
    // ìƒì„¸ ì—ëŸ¬ ë¶„ë¥˜
    const detailedError = createDetailedError(error, {
      model,
      provider: AI_MODELS[model]?.provider,
      action: 'ai-verify'
    })
    
    console.error('AI verification failed:', {
      errorType: detailedError.errorInfo.type,
      message: detailedError.errorInfo.message,
    })
    
    // AI ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ throw (Regex í´ë°± ì—†ìŒ)
    const errorWithInfo = new Error(detailedError.errorInfo.message) as Error & { 
      aiError: typeof detailedError.errorInfo
    }
    errorWithInfo.aiError = detailedError.errorInfo
    throw errorWithInfo
  }
}

/**
 * ğŸ”’ í…ìŠ¤íŠ¸ ì •ê·œí™” (ë¹„êµìš©) - ê°•í™” ë²„ì „
 * - ëª¨ë“  ì¢…ë¥˜ì˜ ê³µë°± ë¬¸ìë¥¼ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ í†µì¼
 * - ìœ ë‹ˆì½”ë“œ ê³µë°±, ì „ê° ê³µë°±, ì¤„ë°”ê¿ˆ ë“± ì²˜ë¦¬
 */
function normalizeText(text: string): string {
  if (!text) return ''
  return text
    // ëª¨ë“  ì¢…ë¥˜ì˜ ê³µë°±/ì¤„ë°”ê¿ˆì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
    .replace(/[\s\u00A0\u2000-\u200B\u2028\u2029\u3000\uFEFF]+/g, ' ')
    // ë‹¤ì–‘í•œ ëŒ€ì‹œ/í•˜ì´í”ˆ ë¬¸ìë¥¼ ì¼ë°˜ í•˜ì´í”ˆìœ¼ë¡œ í†µì¼ (â€•, â€”, â€“, â€ ë“±)
    .replace(/[\u2010-\u2015\u2212\uFE58\uFE63\uFF0D]/g, '-')
    // ë‹¤ì–‘í•œ ë”°ì˜´í‘œë¥¼ ì¼ë°˜ ë”°ì˜´í‘œë¡œ í†µì¼ (', ', ", " ë“±)
    .replace(/[\u2018\u2019\u201A\u201B]/g, "'")
    .replace(/[\u201C\u201D\u201E\u201F]/g, '"')
    // ì¼ë°˜ ë”°ì˜´í‘œ ì œê±° (AIê°€ ì¶”ê°€í•˜ëŠ” ê²½ìš° ëŒ€ì‘)
    .replace(/^["']+|["']+$/g, '')  // ë¬¸ìì—´ ì–‘ë ë”°ì˜´í‘œ ì œê±°
    .replace(/["']\s*$/g, '')  // ëì˜ ë”°ì˜´í‘œ ì œê±°
    .replace(/^\s*["']/g, '')  // ì‹œì‘ì˜ ë”°ì˜´í‘œ ì œê±°
    // ì•ë’¤ ê³µë°± ì œê±°
    .trim()
}

/**
 * ğŸ”’ ìœ ì—°í•œ í…ìŠ¤íŠ¸ ë¹„êµ (ê³µë°± ë¬´ì‹œ)
 * - ê³µë°± ì°¨ì´ëŠ” ë¬´ì‹œí•˜ê³  ì‹¤ì œ ë‚´ìš©ë§Œ ë¹„êµ
 */
function compareTextsFlexibly(original: string, extracted: string): { isMatch: boolean; diff?: string } {
  const normalizedOriginal = normalizeText(original)
  const normalizedExtracted = normalizeText(extracted)
  
  if (normalizedOriginal === normalizedExtracted) {
    return { isMatch: true }
  }
  
  // ì°¨ì´ì  ì°¾ê¸° (ë””ë²„ê¹…ìš©)
  const maxLen = Math.min(normalizedOriginal.length, normalizedExtracted.length, 100)
  let diffIndex = -1
  for (let i = 0; i < maxLen; i++) {
    if (normalizedOriginal[i] !== normalizedExtracted[i]) {
      diffIndex = i
      break
    }
  }
  
  if (diffIndex >= 0) {
    const context = 20
    const start = Math.max(0, diffIndex - context)
    const originalSnippet = normalizedOriginal.substring(start, diffIndex + context)
    const extractedSnippet = normalizedExtracted.substring(start, diffIndex + context)
    return { 
      isMatch: false, 
      diff: `ìœ„ì¹˜ ${diffIndex}: ì›ë³¸[${originalSnippet}] vs AI[${extractedSnippet}]` 
    }
  }
  
  // ê¸¸ì´ ì°¨ì´
  return { 
    isMatch: false, 
    diff: `ê¸¸ì´ ì°¨ì´: ì›ë³¸ ${normalizedOriginal.length}ì vs AI ${normalizedExtracted.length}ì` 
  }
}

/**
 * ğŸ›¡ï¸ ë³‘ë ¬ ë¬¸ì¥ ì¶”ì¶œ (ì˜ì–´+í•œê¸€ ë™ì‹œ ì²˜ë¦¬)
 * í•µì‹¬ ì›ì¹™:
 * - ì˜ì–´ ì›ë¬¸: ì ˆëŒ€ ìˆ˜ì • ë¶ˆê°€
 * - í•œê¸€ í•´ì„: ì ˆëŒ€ ìˆ˜ì • ë¶ˆê°€
 * - ë¬¸ì œ ë°œê²¬ ì‹œ: ê´€ë¦¬ì ì•Œë¦¼ë§Œ
 */
async function extractParallelSentences(
  englishText: string,
  koreanText: string,
  model: ModelId
): Promise<SentenceSplitResult> {
  // ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ì •ê·œí™” (ì…€ ë‚´ ì¤„ë°”ê¿ˆ ì²˜ë¦¬)
  const normalizedEnglish = englishText.trim().replace(/[\r\n]+/g, ' ').replace(/\s+/g, ' ')
  const normalizedKorean = koreanText.trim().replace(/[\r\n]+/g, ' ').replace(/\s+/g, ' ')
  
  // ì›ë³¸ ì €ì¥ (ê²€ì¦ìš©) - ì •ê·œí™”ëœ ë²„ì „ ì‚¬ìš©
  const originalEnglish = normalizedEnglish
  const originalKorean = normalizedKorean
  
  const prompt = `You are extracting sentence pairs from English text and its Korean translation.

**ğŸ”´ ABSOLUTE RULES - VIOLATION = COMPLETE FAILURE:**
1. EXTRACT text EXACTLY as given - NO modifications, corrections, or paraphrasing
2. Every character, space, and punctuation must match the original EXACTLY
3. You are a SPLITTER, not an EDITOR - never "fix" anything
4. If unsure about a split, keep sentences together rather than splitting wrong

**TASK:**
Split into sentence pairs. Each pair = one English sentence + its corresponding Korean translation.

**INPUT:**
English:
"${normalizedEnglish}"

Korean:
"${normalizedKorean}"

**OUTPUT (JSON only, no markdown):**
{
  "pairs": [
    {"no": 1, "english": "Exact English text.", "korean": "ì •í™•í•œ í•œê¸€ í…ìŠ¤íŠ¸."}
  ],
  "confidence": 0.95,
  "korean_issues": [
    {"type": "missing|incomplete|quality", "pairNo": 2, "description": "ë¬¸ì œ ì„¤ëª…"}
  ]
}

**KOREAN ISSUE TYPES (report but NEVER fix):**
- missing: ë²ˆì—­ì´ ëˆ„ë½ëœ ê²½ìš°
- incomplete: ë²ˆì—­ì´ ë¶ˆì™„ì „í•œ ê²½ìš°  
- quality: ë²ˆì—­ í’ˆì§ˆì´ ì˜ì‹¬ë˜ëŠ” ê²½ìš°

REMEMBER: Report issues but NEVER modify any text!`

  const modelInfo = AI_MODELS[model]
  let resultText = ''

  try {
    switch (modelInfo.provider) {
      case 'openai': {
        const client = getOpenAI()
        if (!client) throw new Error('OpenAI API key not configured')
        const response = await client.chat.completions.create({
          model,
          messages: [{ role: 'user', content: prompt }],
          response_format: { type: 'json_object' },
          temperature: 0.1,
        })
        resultText = response.choices[0].message?.content || ''
        break
      }
      case 'anthropic': {
        const client = getAnthropic()
        if (!client) throw new Error('Anthropic API key not configured')
        const response = await client.messages.create({
          model,
          max_tokens: 4096,
          messages: [{ role: 'user', content: prompt }],
        })
        resultText = response.content[0]?.type === 'text' ? response.content[0].text : ''
        break
      }
      case 'google': {
        console.log(`ğŸ”µ Google Gemini í˜¸ì¶œ ì‹œì‘ - ëª¨ë¸: ${model}`)
        const client = getGoogleAI()
        if (!client) {
          console.error('âŒ Google Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
          throw new Error('Google Gemini API key not configured - .env.localì— GOOGLE_GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”')
        }
        try {
          const geminiModel = client.getGenerativeModel({ 
            model,
            generationConfig: { responseMimeType: 'application/json', temperature: 0.1 }
          })
          console.log(`ğŸ”µ Gemini ëª¨ë¸ ìƒì„± ì™„ë£Œ, ì½˜í…ì¸  ìƒì„± ì‹œì‘...`)
          const response = await geminiModel.generateContent(prompt)
          resultText = response.response.text()
          console.log(`âœ… Google Gemini ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (${resultText.length}ì)`)
        } catch (geminiError) {
          console.error('âŒ Google Gemini API ì˜¤ë¥˜:', geminiError)
          throw geminiError
        }
        break
      }
      default:
        throw new Error(`Unsupported provider: ${modelInfo.provider}`)
    }

    console.log(`ğŸ“‹ AI ì‘ë‹µ íŒŒì‹± ì¤‘...`)
    const parsed = JSON.parse(resultText)
    const pairs: SentencePair[] = parsed.pairs || []
    console.log(`âœ… íŒŒì‹± ì™„ë£Œ: ${pairs.length}ê°œ ë¬¸ì¥ ìŒ ì¶”ì¶œ`)
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ğŸ›¡ï¸ ì˜ì–´ ì›ë¬¸ ê²€ì¦ (ì ˆëŒ€ ë¶ˆê°€ì¹¨) - ìœ ì—°í•œ ë¹„êµ
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    const extractedEnglish = pairs.map(p => p.english || '').filter(Boolean).join(' ')
    const englishComparison = compareTextsFlexibly(originalEnglish, extractedEnglish)
    
    if (!englishComparison.isMatch) {
      console.error('âŒ AIê°€ ì˜ì–´ ì›ë¬¸ì„ ìˆ˜ì •í•¨ - ì¬ì‹œë„ í•„ìš”')
      console.error('ì°¨ì´ì :', englishComparison.diff)
      
      // AI ê²°ê³¼ ê±°ë¶€ - ì—ëŸ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¬ì‹œë„ ìœ ë„
      throw new Error('AI_TEXT_MODIFIED: AIê°€ ì˜ì–´ ì›ë¬¸ì„ ë³€í˜•í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
    }
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ğŸ›¡ï¸ í•œê¸€ í•´ì„ ê²€ì¦ (ìœ ì—°í•˜ê²Œ ì²˜ë¦¬ - ê²½ê³ ë§Œ í‘œì‹œ)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    const extractedKorean = pairs.map(p => p.korean || '').filter(Boolean).join(' ')
    const koreanComparison = compareTextsFlexibly(originalKorean, extractedKorean)
    
    const koreanIssues: KoreanIssue[] = []
    
    if (!koreanComparison.isMatch) {
      // ê¸¸ì´ ì°¨ì´ ê³„ì‚° (ë¯¸ë¯¸í•œ ì°¨ì´ëŠ” ë¬´ì‹œ)
      const originalLen = normalizeText(originalKorean).length
      const extractedLen = normalizeText(extractedKorean).length
      const lengthDiff = Math.abs(originalLen - extractedLen)
      const lengthRatio = originalLen > 0 ? lengthDiff / originalLen : 0
      
      // 5ì ì´ë‚´ ë˜ëŠ” 1% ì´ë‚´ ì°¨ì´ëŠ” ë¬´ì‹œ (ê³µë°±, ë¬¸ì¥ë¶€í˜¸ ì •ë„)
      if (lengthDiff <= 5 || lengthRatio <= 0.01) {
        console.log('â„¹ï¸ í•œê¸€ ë¯¸ë¯¸í•œ ì°¨ì´ ë¬´ì‹œ:', koreanComparison.diff, `(${lengthDiff}ì, ${(lengthRatio * 100).toFixed(1)}%)`)
      } else {
        // ìœ ì˜ë¯¸í•œ ì°¨ì´ë§Œ ê²½ê³ 
        console.warn('âš ï¸ AIê°€ í•œê¸€ í•´ì„ì„ ì¼ë¶€ ìˆ˜ì •í•¨ - í—ˆìš©ë¨')
        console.warn('ì°¨ì´ì :', koreanComparison.diff, `(${lengthDiff}ì, ${(lengthRatio * 100).toFixed(1)}%)`)
        
        // ì—ëŸ¬ ëŒ€ì‹  ê²½ê³ ë¡œ ê¸°ë¡ â†’ ì‚¬ìš©ìê°€ í™•ì¸
        koreanIssues.push({
          type: 'modified',
          pairNo: 0,
          description: `í•œê¸€ í•´ì„ì´ ì¼ë¶€ ìˆ˜ì •ë¨: ${koreanComparison.diff}`,
          severity: 'medium',
          needsReview: true,
        })
      }
    }
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ğŸ” í•œê¸€ í’ˆì§ˆ ë¬¸ì œ ê°ì§€ â†’ ê´€ë¦¬ì ì•Œë¦¼ (ìˆ˜ì • X)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    // AIê°€ ê°ì§€í•œ ë¬¸ì œë“¤ ì¶”ê°€
    if (parsed.korean_issues && Array.isArray(parsed.korean_issues)) {
      for (const issue of parsed.korean_issues) {
        koreanIssues.push({
          type: issue.type || 'quality',
          pairNo: issue.pairNo,
          description: issue.description || 'í•œê¸€ ë²ˆì—­ í’ˆì§ˆ ë¬¸ì œ',
          severity: 'medium',
          needsReview: true,
        })
      }
    }
    
    // ì¶”ê°€ í’ˆì§ˆ ì²´í¬ (ìë™ ê°ì§€)
    for (const pair of pairs) {
      // ì˜ì–´ ì›ë¬¸ ëˆ„ë½ ì²´í¬
      if (!pair.english || pair.english.trim().length === 0) {
        console.warn(`âš ï¸ ë¬¸ì¥ ${pair.no}ì˜ ì˜ì–´ ì›ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤ - ê±´ë„ˆëœ€`)
        continue
      }
      
      // í•œê¸€ ë²ˆì—­ ëˆ„ë½
      if (!pair.korean || pair.korean.trim().length === 0) {
        koreanIssues.push({
          type: 'missing',
          pairNo: pair.no,
          description: `ë¬¸ì¥ ${pair.no}ì˜ í•œê¸€ ë²ˆì—­ì´ ì—†ìŠµë‹ˆë‹¤`,
          severity: 'high',
          needsReview: true,
        })
      }
      
      // í•œê¸€ì´ ë„ˆë¬´ ì§§ìŒ (ì˜ì–´ ëŒ€ë¹„) - ì„ê³„ê°’ ì™„í™”: ë‹¨ì–´ Ã— 1.2
      const enWords = (pair.english || '').split(/\s+/).length
      const krChars = (pair.korean?.match(/[ê°€-í£]/g) || []).length
      // ì˜ì–´ 10ë‹¨ì–´ ì´ìƒì´ê³ , í•œê¸€ì´ ì˜ì–´ ë‹¨ì–´ ìˆ˜ Ã— 1.2ë³´ë‹¤ ì ì€ ê²½ìš°ë§Œ ê²½ê³ 
      if (enWords > 10 && krChars < enWords * 1.2) {
        koreanIssues.push({
          type: 'incomplete',
          pairNo: pair.no,
          description: `ë¬¸ì¥ ${pair.no}ì˜ í•œê¸€ ë²ˆì—­ì´ ì§§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì˜ì–´ ${enWords}ë‹¨ì–´, í•œê¸€ ${krChars}ì) - ì°¸ê³ ìš©`,
          severity: 'low',  // medium â†’ lowë¡œ í•˜í–¥
          needsReview: false,  // ìë™ ì•Œë¦¼ ë¹„í™œì„±í™”
        })
      }
      
      // ì˜ì–´ ë‹¨ì–´ê°€ í•œê¸€ì— ê·¸ëŒ€ë¡œ ìˆëŠ” ê²½ìš° (ë²ˆì—­ ì•ˆ ë¨) - ì„ê³„ê°’ ì™„í™”
      const englishWordsInKorean = pair.korean?.match(/[a-zA-Z]{4,}/g) || []
      if (englishWordsInKorean.length > 5) {  // 2 â†’ 5ë¡œ ì™„í™”
        koreanIssues.push({
          type: 'quality',
          pairNo: pair.no,
          description: `ë¬¸ì¥ ${pair.no}ì— ì˜ì–´ ë‹¨ì–´ê°€ ë§ìŠµë‹ˆë‹¤: ${englishWordsInKorean.slice(0, 3).join(', ')} - ì°¸ê³ ìš©`,
          severity: 'low',
          needsReview: false,
        })
      }
    }
    
    // ê²°ê³¼ ìƒì„± (ìœ íš¨í•œ pairë§Œ)
    const sentences: ParsedSentence[] = pairs
      .filter(p => p.english && p.english.trim().length > 0)
      .map(p => ({
        no: p.no,
        content: p.english,  // ì›ë¬¸ ê·¸ëŒ€ë¡œ
        koreanTranslation: p.korean || '',  // í•´ì„ ê·¸ëŒ€ë¡œ
        wordCount: (p.english || '').split(/\s+/).length,
        confidence: p.confidence || 0.95,
        issues: [],
      }))
    
    return {
      sentences,
      confidence: parsed.confidence || 0.95,
      method: 'parallel',
      model,
      warnings: koreanIssues.length > 0 
        ? [`âš ï¸ í•œê¸€ ë²ˆì—­ì— ${koreanIssues.length}ê°œì˜ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.`]
        : undefined,
      koreanIssues: koreanIssues.length > 0 ? koreanIssues : undefined,
    }
  } catch (error) {
    // ìƒì„¸ ì—ëŸ¬ ë¶„ë¥˜
    const detailedError = createDetailedError(error, {
      model,
      provider: AI_MODELS[model]?.provider,
      action: 'parallel-extraction'
    })
    
    console.error('Parallel extraction failed:', {
      errorType: detailedError.errorInfo.type,
      message: detailedError.errorInfo.message,
      originalError: detailedError.originalError,
      model,
    })
    
    // ëŒ€ì•ˆ ëª¨ë¸ ì¶”ì²œ
    const alternativeModel = getAlternativeModel(model, detailedError.errorInfo.type)
    
    // AI ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ throw (Regex í´ë°± ì—†ìŒ)
    const errorWithInfo = new Error(detailedError.errorInfo.message) as Error & { 
      aiError: typeof detailedError.errorInfo & { alternativeModel?: string }
    }
    errorWithInfo.aiError = {
      ...detailedError.errorInfo,
      alternativeModel,
    }
    throw errorWithInfo
  }
}

/**
 * POST /api/sentence-split
 * ë¬¸ì¥ ë¶„ë¦¬ API
 */
export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { 
      text, 
      koreanText,
      model = 'gemini-2.0-flash' as ModelId,
      mode = 'parallel', // 'regex' | 'ai' | 'hybrid' | 'ai-verify' | 'parallel'
      includeTranslationAnalysis = true,
    } = body

    if (!text || text.trim().length === 0) {
      return NextResponse.json(
        { error: 'Text is required' },
        { status: 400 }
      )
    }

    const startTime = Date.now()
    let result: SentenceSplitResult

    switch (mode) {
      case 'regex':
        result = splitSentences(text, koreanText)
        break
      
      case 'ai':
        result = await splitWithAI(text, model as ModelId, koreanText)
        break
      
      case 'ai-verify':
        result = await splitWithAIVerification(text, model as ModelId, koreanText)
        break
      
      case 'hybrid':
        result = await splitHybrid(text, model as ModelId, koreanText)
        break
      
      case 'parallel':
      default:
        // í•œê¸€ ë²ˆì—­ì´ ìˆìœ¼ë©´ ë³‘ë ¬ ì¶”ì¶œ, ì—†ìœ¼ë©´ AI ê²€ì¦
        if (koreanText && koreanText.trim().length > 0) {
          result = await extractParallelSentences(text, koreanText, model as ModelId)
        } else {
          result = await splitWithAIVerification(text, model as ModelId, koreanText)
        }
        break
    }

    // ë²ˆì—­ ë¶„ì„ (ì˜µì…˜)
    let translationStatus = null
    if (includeTranslationAnalysis && koreanText) {
      const baseAnalysis = analyzeTranslation(text, koreanText)
      
      // AI parallel ëª¨ë“œì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë¶„ë¦¬í–ˆë‹¤ë©´ AI ê²°ê³¼ë¥¼ ì‹ ë¢°
      if (result.method === 'parallel' && result.sentences.length > 0) {
        const koreanSentenceCount = result.sentences.filter(s => s.koreanTranslation).length
        translationStatus = {
          ...baseAnalysis,
          // AI ë¶„ë¦¬ ê²°ê³¼ë¡œ ë®ì–´ì“°ê¸°
          sentenceCount: { 
            english: result.sentences.length, 
            korean: koreanSentenceCount 
          },
          alignment: result.sentences.length === koreanSentenceCount ? 'perfect' : baseAnalysis.alignment,
          // AIê°€ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ì‹ ë¢°ë„ ìƒí–¥
          quality: result.confidence > 0.9 ? 'good' : baseAnalysis.quality,
          needsAI: false,  // AIê°€ ì´ë¯¸ ì²˜ë¦¬í•¨
          // AI ë¶„ë¦¬ ì„±ê³µ ì‹œ Regex ë¶ˆì¼ì¹˜ ê²½ê³  ì œê±°
          signals: baseAnalysis.signals.filter((s: string) => 
            !s.includes('ë¬¸ì¥ ê°œìˆ˜ ë¶ˆì¼ì¹˜')
          ),
        }
      } else {
        translationStatus = baseAnalysis
      }
    }

    const responseTime = Date.now() - startTime

    return NextResponse.json({
      success: true,
      ...result,
      translationStatus,
      responseTime,
      stats: {
        sentenceCount: result.sentences.length,
        totalWords: result.sentences.reduce((sum, s) => sum + s.wordCount, 0),
        avgWordsPerSentence: result.sentences.length > 0 
          ? Math.round(result.sentences.reduce((sum, s) => sum + s.wordCount, 0) / result.sentences.length)
          : 0,
      },
    })
  } catch (error) {
    console.error('Sentence split error:', error)
    
    // AI ì—ëŸ¬ ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
    const aiError = (error as Error & { aiError?: unknown })?.aiError
    
    return NextResponse.json(
      { 
        success: false, 
        error: error instanceof Error ? error.message : 'Unknown error',
        aiError,
        canRetry: true,
      },
      { status: 500 }
    )
  }
}

/**
 * POST /api/sentence-split/batch
 * ë°°ì¹˜ ë¬¸ì¥ ë¶„ë¦¬ (ì—¬ëŸ¬ ì§€ë¬¸)
 */
export async function PUT(request: NextRequest) {
  try {
    const body = await request.json()
    const { 
      passages,
      model = 'gemini-2.0-flash' as ModelId,
      mode = 'parallel',
    } = body

    if (!passages || !Array.isArray(passages) || passages.length === 0) {
      return NextResponse.json(
        { error: 'Passages array is required' },
        { status: 400 }
      )
    }

    const results = []
    const startTime = Date.now()

    for (const passage of passages) {
      try {
        let result: SentenceSplitResult

        switch (mode) {
          case 'regex':
            result = splitSentences(passage.content, passage.koreanTranslation)
            break
          
          case 'ai':
            result = await splitWithAI(passage.content, model as ModelId, passage.koreanTranslation)
            break
          
          case 'ai-verify':
            result = await splitWithAIVerification(passage.content, model as ModelId, passage.koreanTranslation)
            break
          
          case 'hybrid':
            result = await splitHybrid(passage.content, model as ModelId, passage.koreanTranslation)
            break
          
          case 'parallel':
          default:
            // í•œê¸€ ë²ˆì—­ì´ ìˆìœ¼ë©´ ë³‘ë ¬ ì¶”ì¶œ, ì—†ìœ¼ë©´ AI ê²€ì¦
            if (passage.koreanTranslation && passage.koreanTranslation.trim().length > 0) {
              result = await extractParallelSentences(passage.content, passage.koreanTranslation, model as ModelId)
            } else {
              result = await splitWithAIVerification(passage.content, model as ModelId, passage.koreanTranslation)
            }
            break
        }

        const translationStatus = passage.koreanTranslation 
          ? analyzeTranslation(passage.content, passage.koreanTranslation)
          : null

        results.push({
          passageId: passage.id,
          passageName: passage.name,
          success: true,
          ...result,
          translationStatus,
        })
      } catch (error) {
        results.push({
          passageId: passage.id,
          passageName: passage.name,
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error',
        })
      }
    }

    const responseTime = Date.now() - startTime
    const successCount = results.filter(r => r.success).length

    return NextResponse.json({
      success: true,
      results,
      summary: {
        total: passages.length,
        success: successCount,
        failed: passages.length - successCount,
        totalSentences: results.reduce((sum, r) => sum + (r.sentences?.length || 0), 0),
      },
      responseTime,
      model,
      mode,
    })
  } catch (error) {
    console.error('Batch sentence split error:', error)
    return NextResponse.json(
      { 
        success: false, 
        error: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    )
  }
}

